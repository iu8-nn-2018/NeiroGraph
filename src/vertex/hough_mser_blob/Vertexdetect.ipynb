{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Links\n",
    "\n",
    "### https://stackoverflow.com/questions/10716464/what-are-the-correct-usage-parameter-values-for-houghcircles-in-opencv-for-iris\n",
    "\n",
    "### https://stackoverflow.com/questions/9860667/writing-robust-color-and-size-invariant-circle-detection-with-opencv-based-on\n",
    "\n",
    "## HOUGH Detect\n",
    "### Parameters\n",
    "- image\t8-bit, single-channel, grayscale input image.\n",
    "- circles\tOutput vector of found circles. Each vector is encoded as a 3-element floating-point vector (x,y,radius) .\n",
    "- method\tDetection method, see cv::HoughModes. Currently, the only implemented method is HOUGH_GRADIENT\n",
    "- dp\tInverse ratio of the accumulator resolution to the image resolution. For example, if dp=1 , the accumulator has the same resolution as the input image. If dp=2 , the accumulator has half as big width and height.\n",
    "- minDist\tMinimum distance between the centers of the detected circles. If the parameter is too small, multiple neighbor circles may be falsely detected in addition to a true one. If it is too large, some circles may be missed.\n",
    "- param1\tFirst method-specific parameter. In case of CV_HOUGH_GRADIENT , it is the higher threshold of the two passed to the Canny edge detector (the lower one is twice smaller).\n",
    "- param2\tSecond method-specific parameter. In case of CV_HOUGH_GRADIENT , it is the accumulator threshold for the circle centers at the detection stage. The smaller it is, the more false circles may be detected. Circles, corresponding to the larger accumulator values, will be returned first.\n",
    "- minRadius\tMinimum circle radius.\n",
    "- maxRadius\tMaximum circle radius."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get position vertex\n",
    "### HoughCircles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "center= (219, 235) radius= 44\n",
      "center= (91, 41) radius= 27\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def drawcircles(circles, src):\n",
    "    if circles is not None:\n",
    "        circles = np.uint16(np.around(circles))\n",
    "        for i in circles[0, :]:\n",
    "            center = (i[0], i[1])\n",
    "            print('center=', center, end=' ')\n",
    "            # circle center\n",
    "            cv.circle(src, center, 1, (0, 100, 100), 3)\n",
    "            # circle outline\n",
    "            radius = i[2]\n",
    "            print('radius=', radius, end='\\n')\n",
    "            cv.circle(src, center, radius, (255, 0, 255), 3)\n",
    "\n",
    "def recognitioncircles(src, iter=3):\n",
    "    # HOUGH DETECT\n",
    "    # filters\n",
    "    # GRAY\n",
    "    gray = cv.cvtColor(src, cv.COLOR_BGR2GRAY)\n",
    "    # delete noise\n",
    "    gaus = cv.GaussianBlur(gray, (5, 5), 2)\n",
    "    # cv.imwrite(\"gaus.jpg\", gaus)\n",
    "\n",
    "    rows = gray.shape[0]\n",
    "    h, w = src.shape[:2]\n",
    "\n",
    "    # const\n",
    "    par1 = 90 #90 #80 #40\n",
    "    par2 = 70 #68 #50 #67\n",
    "    minR = 2\n",
    "    maxR = 63\n",
    "    \n",
    "    circles = cv.HoughCircles(gaus, cv.HOUGH_GRADIENT, 2, 2*maxR,\n",
    "                          param1=par1, param2=par2,\n",
    "                          minRadius=minR, maxRadius=maxR)\n",
    "    \n",
    "    drawcircles(circles, src)\n",
    "    cv.imwrite(\"detect.jpg\", src)\n",
    "    \n",
    "    \n",
    "# Loads an image\n",
    "src = cv.imread(\"2.jpg\", cv.IMREAD_COLOR)\n",
    "# Check if image is loaded fine\n",
    "if src is None:\n",
    "    print ('Error opening image!')\n",
    "    print ('Usage: hough_circle.py [image_name -- default ' + file + '] \\n')\n",
    "    \n",
    "recognitioncircles(src)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MSER Blob Detector\n",
    "### 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "orig = cv2.imread(\"2.jpg\")\n",
    "img = orig.copy()\n",
    "img2 = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "# kernel = np.ones((5,5), np.uint8)\n",
    "# img2 = cv2.erode(img2, kernel, iterations = 1)\n",
    "#img2 = cv2.GaussianBlur(img2,(5,5),2)\n",
    "img2 = cv2.Canny(img2, 100, 255)\n",
    "\n",
    "detector = cv2.MSER_create()\n",
    "fs = detector.detect(img2)\n",
    "fs.sort(key = lambda x: -x.size)\n",
    "\n",
    "def supress(x):\n",
    "        for f in fs:\n",
    "                distx = f.pt[0] - x.pt[0]\n",
    "                disty = f.pt[1] - x.pt[1]\n",
    "                dist = math.sqrt(distx*distx + disty*disty)\n",
    "                if (f.size > x.size) and (dist<f.size/2):\n",
    "                        return True\n",
    "\n",
    "sfs = [x for x in fs if not supress(x)]\n",
    "\n",
    "for f in sfs:\n",
    "        cv2.circle(img, (int(f.pt[0]), int(f.pt[1])), int(f.size/2), (150, 55, 65), 2, cv2.LINE_AA)\n",
    "        cv2.circle(img, (int(f.pt[0]), int(f.pt[1])), int(f.size/2), (250, 200, 200), 1, cv2.LINE_AA)\n",
    "\n",
    "h, w = orig.shape[:2]\n",
    "vis = np.zeros((h, w*2+5), np.uint8)\n",
    "vis = cv2.cvtColor(vis, cv2.COLOR_GRAY2BGR)\n",
    "vis[:h, :w] = orig\n",
    "vis[:h, w+5:w*2+5] = img\n",
    "\n",
    "# cv2.imshow(\"image\", vis)\n",
    "cv2.imwrite(\"c_o.jpg\", vis)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 http://qaru.site/questions/1242600/why-houghcircles-returns-0-circles-while-trying-to-detect-irises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "def non_maximal_supression(x):\n",
    "    for f in features:\n",
    "        distx = f.pt[0] - x.pt[0]\n",
    "        disty = f.pt[1] - x.pt[1]\n",
    "        dist = math.sqrt(distx*distx + disty*disty)\n",
    "        if (f.size > x.size) and (dist<f.size/2):\n",
    "            return True\n",
    "\n",
    "thresh = 70\n",
    "img = cv2.imread(\"121.jpg\")\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "#erosion = cv2.GaussianBlur(bw, (5, 5), 2)\n",
    "bw = cv2.Canny(gray, 100, 255)\n",
    "# erosion = cv2.medianBlur(bw, 5)\n",
    "# kernel = np.ones((5,5), np.uint8)\n",
    "# bw = cv2.erode(erosion, kernel, iterations = 2)\n",
    "\n",
    "detector = cv2.MSER_create()\n",
    "features = detector.detect(bw)\n",
    "# coordinates, bboxes = detector.detectRegions(gray)\n",
    "\n",
    "features.sort(key = lambda x: -x.size)\n",
    "\n",
    "features = [ x for x in features if (x.size > 40)] \n",
    "reduced_features = [x for x in features if not non_maximal_supression(x)]\n",
    "\n",
    "for rf in reduced_features:\n",
    "    cv2.circle(img, (int(rf.pt[0]), int(rf.pt[1])), int(rf.size/2), (0,0,255), 3)\n",
    "\n",
    "# cv2.imshow(\"iris detection\", img)\n",
    "cv2.imwrite(\"iris detection.jpg\", img)\n",
    "# cv2.waitKey()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the Center of a Blob (Centroid) using OpenCV\n",
    "### https://www.learnopencv.com/find-center-of-blob-centroid-using-opencv-cpp-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "# read image\n",
    "img = cv2.imread(\"58.jpg\")\n",
    " \n",
    "# convert the image to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "gray_image = cv2.Canny(gray, 100, 255)\n",
    "# cv2.imshow('Canny',gray_image)\n",
    " \n",
    "# convert the grayscale image to binary image\n",
    "ret,thresh = cv2.threshold(gray_image,127,255,0)\n",
    "# cv2.imshow(\"thresh\", thresh)\n",
    " \n",
    "# find contours in the binary image\n",
    "im2, contours, hierarchy = cv2.findContours(thresh,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "cv2.imshow(\"im2\", im2)\n",
    "\n",
    "for c in contours:\n",
    "   # calculate moments for each contour\n",
    "    M = cv2.moments(c)\n",
    " \n",
    "   # calculate x,y coordinate of center\n",
    "    cX = 0\n",
    "    cY = 0\n",
    "    if M[\"m00\"] != 0:\n",
    "        cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "        cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "    \n",
    "    cv2.circle(img, (cX, cY), 5, (255, 255, 255), -1)\n",
    "#         cv2.putText(img, \"c\", (cX - 25, cY - 25),cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    " \n",
    "# display the image\n",
    "cv2.imshow(\"Image\", img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple blob detector\n",
    "### http://qaru.site/questions/180029/how-to-use-opencv-simpleblobdetector\n",
    "### https://www.learnopencv.com/blob-detection-using-opencv-python-c/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Read image\n",
    "im = cv2.imread(\"63.jpg\")\n",
    "\n",
    "# Setup SimpleBlobDetector parameters.\n",
    "params = cv2.SimpleBlobDetector_Params()\n",
    "\n",
    "# Change thresholds\n",
    "params.minThreshold = 10\n",
    "params.maxThreshold = 200\n",
    "\n",
    "# Filter by Area.\n",
    "params.filterByArea = True\n",
    "params.minArea = 1500\n",
    "\n",
    "# Filter by Circularity\n",
    "params.filterByCircularity = True\n",
    "params.minCircularity = 0.01\n",
    "\n",
    "# Filter by Convexity\n",
    "params.filterByConvexity = True\n",
    "params.minConvexity = 0.81\n",
    "\n",
    "# Filter by Inertia\n",
    "params.filterByInertia = True\n",
    "params.minInertiaRatio = 0.01\n",
    "\n",
    "# Create a detector with the parameters\n",
    "detector = cv2.SimpleBlobDetector_create(params)\n",
    "\n",
    "# filters\n",
    "gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "im = cv2.Canny(gray, 100, 255)\n",
    "\n",
    "# Detect blobs.\n",
    "keypoints = detector.detect(im)\n",
    "\n",
    "# Draw detected blobs as red circles.\n",
    "# cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS ensures\n",
    "# the size of the circle corresponds to the size of blob\n",
    "\n",
    "im_with_keypoints = cv2.drawKeypoints(im, keypoints, np.array([]), (0,0,255), cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "# Show blobs\n",
    "cv2.imshow(\"Keypoints\", im_with_keypoints)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Read image\n",
    "im = cv2.imread(\"63.jpg\")\n",
    "\n",
    "detector = cv2.SimpleBlobDetector_create()\n",
    "\n",
    "gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "# kernel = np.ones((5,5), np.uint8)\n",
    "# erosion = cv2.erode(gray, kernel, iterations = 1)\n",
    "#thresh = cv2.GaussianBlur(gray, (5, 5), 2)\n",
    "im = cv2.Canny(gray, 100, 255)\n",
    "\n",
    "# Detect blobs.\n",
    "keypoints = detector.detect(im)\n",
    "\n",
    "# Draw detected blobs as red circles.\n",
    "# cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS ensures\n",
    "# the size of the circle corresponds to the size of blob\n",
    "\n",
    "im_with_keypoints = cv2.drawKeypoints(im, keypoints, np.array([]), (0,0,255), cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "# Show blobs\n",
    "cv2.imshow(\"Keypoints\", im_with_keypoints)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
